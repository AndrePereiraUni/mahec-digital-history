---
title: Session Summaries by Sabrina Morais
abstract: 'Summaries'
authors:
  - Sabrina-Morais001
date: YYYY-MM-DD
---

## Data Metadata & Tool 2 'Tropy', 25.09.2024
Before the course on “Data and metadata”, we also had to watch a video and read a text so that we could get an impression of the topic and gain a basic understanding. In the lecture we briefly saw what digital history is. Data are facts or pieces of information, and they come in many different types. So data are digital things that we collect, store, manipulate, examine, interpret, preserve and create/produce. We also learned what research data is, which are factual records used as primary sources for scientific research. Metadata are information about information, and is used to find, organize, identify, contextualise data and to evaluate an information. It allows us to filter objects by characteristics, tags and types. Metadata allows the researcher to organize the data sets. Through the examples and videos, it was easier to understand metadata and data. Whenever a term was explained, there were examples to help us visualise it, which was ideal. I also didn't realise that we also produce data or metadata in our everyday lives, for example by posting a tweet. So text, hashtag, time, date, etc. would be the metadata. Historians/researchers use data/metadate because they improve accessibility, organisation/classification, quality and accuracy/reliability of research. Unfortunately, the introduction via Tropy was very short and rapid. But I understood that Tropy allows us to organize, comment and describe photographs of research material, but it does not keep track of references (not organizing citation) and create bibliographies, alter photo files with advanced tools or publish the photo files online.


## Web Archives', 02.10.2024
In the course on web archives we got new impressions of different web archives, including how they work, what their problems might be and how useful they can be for historians/researchers. There were 7 different assignments. For each assignment we had to set up groups of 3-4 students and had 30 minutes to answer the different questions and divide the group work. At the end, each group had to present their results to the class. I worked with two other students on “Fluidity of the web” on Ranke.2, respectively on the historical narratives in constant motion, thus on a Wikipedia entry about September 11 attack. At the beginning, we worked individually and then presented our findings to each other. We had to analyse the revision history for editing changes. There were more grammar/spelling corrections, adding images/text/paragraphs, removing tags, correcting links and restructuring the text in the article. In this editing history, some bots were also found and make rapid repetitive semantic or semi-automatic edits, correcting spelling errors, removing vandalism and fixing formatting errors. Bots can’t recognize when databases include incomplete information or mistakes. Bots are created by humans, which means they depend on the assistance of humans, so the bot can adopt biases from the editors. Bots don’t focus on contextualisation, critical thinking or on ethical consideration. The collaboration between humans and bots changes how history is captured, produced and understood, so questions of reliability, objectivity and authenticity can arise. Historical narratives on Wikipedia are in constant flux. For example, the way historians analyse and write about the past can change over time, there are new discoveries, new historical research about a certain topic and different interpretations and perspectives. Wikipedia is publicly accessible, which means that anyone can edit the article, so incorrect information or even vandalism can occur. The aim of this exercise was to understand how collaborative technologies influence the moving nature of web content.





