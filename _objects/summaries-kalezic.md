---
title: Session Summaries by Jelena Kalezic
abstract: 'Bla bla bla bla'
authors:
  - jelena-kalezic
date: 2024-10-08
---

## Summary Session 2, 25 September 2024

In the second session of the course, we explored the evolving role of digital tools and data in historical research. We began by discussing the distinction between digital history and history in the digital age. While not all historians are "digital historians," many engage with digital sources in their work. We also examined how digital history allows for new methods of analyzing and interpreting primary sources, which are now available as electronic data. We delved into the concept of data, tracing its origin back to ancient Greece and its transformation into a key term in modern languages, signifying information that can be measured or analyzed. We also learned about metadata, which is essential for organizing and retrieving information in the digital world. Metadata provides context, helping historians assess the reliability and relevance of sources. One interesting aspect was the discussion of "data as capta," emphasizing the human role in actively shaping and interpreting data, rather than seeing it as merely given. Additionally, we explored research phases—heuristics, analysis, hermeneutics, dissemination, and preservation—and how digital tools enhance these processes. Through tools like Google Books Ngram Viewer and Tropy, we saw practical applications of these concepts, aiding historians in managing, analyzing, and presenting research. Overall, the session emphases the importance of critical engagement with digital sources, as well as the potential and challenges posed by the digital transformation of historical research.

## Summary Session 3, 02 October 2024

In the third session of the course, we presented and analyzed various online archiving platforms. My group presented on crowdsourced born-digital archives, specifically focusing on the September 11 Digital Archive. This platform, created by the Alfred P. Sloan Foundation and others, gathers personal accounts, art, audio, and more. However, one significant issue we encountered was the lack of information on some sources, which made it difficult to assess their reliability for historical research. For example, many art pieces were credited to unknown authors, creating confusion about ownership and authenticity. Several other groups also faced similar challenges regarding access and copyright. For instance, the presentation on the Luxembourg Web Archive highlighted copyright restrictions that limited the ability to archive all relevant websites. Similarly, the family and personal archives group encounter broken links and copyright issue, making it challenging to share these archives effectively. The presentations revealed that while archiving digital content is valuable for preserving history, it also presents significant issues, particularly around access, copyright, and source reliability. The course was useful in showing how divers digital platforms approach these challenges differently, and it highlighted the ongoing work needed to make digital archives more comprehensive and accessible. Overall, this session helped me understand the complexities involved in digital archiving and the importance of critical evaluation when using online platforms for historical research.

## Summary Session 4, 09 October 2024

In our course on machine learning and historical media, we explored how the Impresso project links data, people, disciplines, etc. to study old newspapers. We learned that newspapers are rich source of information, reflecting the ideas and beliefs of past societies. In the newspaper, we can get an idea of what people wore, how they sold food, and how they lived. These newspapers have been digitized, and we can now use machines to search through them easily. During the demo, we used the Impresso website to find out how often certain words appeared in historical newspapers. For example, we searched for words like "Atomkraft" and "nucléaire," and we saw how often they were mentioned in different countries over time. We also learned about "tokens" which are small units like words, used for counting how often something appears in the data. At the end, we did a hands-on activity in groups. My group, Group 3, worked on an Ngrams project. We searched for the term “Plan Marshall” and found it in over 68,000 mentions in 43,617 articles, with most appearing between 1948 and 1951. We discovered that language filters only worked with single tokens like "Marshall." Overall, what I took away from this course is that the group project helped us learn how to use machine learning to find patterns in historical newspapers and better understand how information was shared in the past. Finally, we learned how to use Github to submit our homework. This project helped us see how machine learning can uncover patterns in history through old newspapers. 
